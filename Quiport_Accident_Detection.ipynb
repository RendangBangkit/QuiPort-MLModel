{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quiport - Accident Detection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "POgEQvAzqUyz"
      },
      "source": [
        "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/ && echo 'Done'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqEe7NFdqdPg"
      },
      "source": [
        "!kaggle datasets download -d jerrinbright/accident"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS0ecUc3sAzP"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "from os import getcwd\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-lGUGHy3gEg"
      },
      "source": [
        "!unzip accident.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKM6PrHvbF8f"
      },
      "source": [
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "# YOUR CODE STARTS HERE    \n",
        "    all_files = []\n",
        "    for i in os.listdir(SOURCE):\n",
        "        path = SOURCE + i\n",
        "        if os.path.getsize(path):\n",
        "            all_files.append(i)\n",
        "    \n",
        "    n = len(all_files)\n",
        "    d = int(n * SPLIT_SIZE)\n",
        "    rand = random.sample(all_files, n)\n",
        "    train = rand[:d]\n",
        "    valid = rand[d:]\n",
        "    \n",
        "    for i in train:\n",
        "        copyfile(SOURCE + i, TRAINING + i)\n",
        "        \n",
        "    for i in valid:\n",
        "        copyfile(SOURCE + i, TESTING + i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MrtuR_Ib_C4"
      },
      "source": [
        "folders = [\n",
        "    '/content/accident_detection',\n",
        "    '/content/accident_detection/training',\n",
        "    '/content/accident_detection/testing',\n",
        "    '/content/accident_detection/training/accident',\n",
        "    '/content/accident_detection/training/nonaccident',\n",
        "    '/content/accident_detection/testing/accident',\n",
        "    '/content/accident_detection/testing/nonaccident/',\n",
        "]\n",
        "for i in folders:\n",
        "    try:\n",
        "        os.mkdir(i)\n",
        "    except OSError:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8b_jtoeXst8"
      },
      "source": [
        "accident_dir = '/content/ACCIDENT_DATASET/Accident/'\n",
        "nonaccident_dir = '/content/ACCIDENT_DATASET/No Accident/'\n",
        "train_accident_dir = '/content/accident_detection/training/accident/'\n",
        "test_accident_dir = '/content/accident_detection/testing/accident/'\n",
        "train_nonaccident_dir = '/content/accident_detection/training/nonaccident/'\n",
        "test_nonaccident_dir = '/content/accident_detection/testing/nonaccident/'\n",
        "\n",
        "split_size = .7\n",
        "split_data(accident_dir, train_accident_dir, test_accident_dir, split_size)\n",
        "split_data(nonaccident_dir, train_nonaccident_dir, test_nonaccident_dir, split_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOtLsZhOat7u"
      },
      "source": [
        "print('jumlah training img dengan kecelakaan : {}'.format(len(os.listdir(train_accident_dir))))\n",
        "print('jumlah testing img dengan kecelakaan : {}'.format(len(os.listdir(test_accident_dir))))\n",
        "print('jumlah training img tanpa kecelakaan : {}'.format(len(os.listdir(train_nonaccident_dir))))\n",
        "print('jumlah testing img tanpa kecelakaan : {}'.format(len(os.listdir(test_nonaccident_dir))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSHBe5lIicpm"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2), \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'), \n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "path_model='model_kecelakaan.h5'\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YxJ7d62ipbQ"
      },
      "source": [
        "train_dir = '/content/accident_detection/training/'\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=10,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150)) \n",
        "\n",
        "test_dir = '/content/accident_detection/testing/'\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  batch_size=10,\n",
        "                                                  class_mode  = 'binary',\n",
        "                                                  target_size = (150, 150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5qZRibKjiF4"
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=15,\n",
        "                              verbose=1,\n",
        "                              validation_data=test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdNS03YakJSI"
      },
      "source": [
        "%matplotlib inline\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF8KjBn4vlZg"
      },
      "source": [
        "model.save(\"kecelakaan.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}